{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling possession value using neural network\n",
    "\n",
    "In soccer/football, estimate value of each players action on the field is a critical part of analytics, since we can thus understand the risk and reward of each pass or tackle, and players could have a better decision making in the future. It's also sometimes called possession value.\n",
    "\n",
    "There are quite a few works that estimate possession values inclduing\n",
    "\n",
    "[Karun Singh's expected threat](https://karun.in/blog/expected-threat.html), \n",
    "\n",
    "[@thecomeonman xPo](https://thecomeonman.github.io/xPo/),\n",
    "\n",
    "[Tom Decroos et al. VAEP](https://arxiv.org/abs/1802.07127),\n",
    "\n",
    "but due to limitation of data access, all of these works are base on event data only and hence dependent of data provider and can't capture everything on the field. With [Metrica sports sample tracking data](https://github.com/metrica-sports/sample-data) we can now try to estimate using player position and speed instead.\n",
    "\n",
    "\n",
    "In NFL big data bowl 2020 which provide tracking data to model NFL competition, and the [winning solution](https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/119400) ultilize a convolutional neural network and the following code is attempt of depolying similar model to estimate shot attempt chance with tracking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS              964\n",
      "CHALLENGE         311\n",
      "RECOVERY          248\n",
      "BALL LOST         233\n",
      "SET PIECE          80\n",
      "BALL OUT           49\n",
      "SHOT               24\n",
      "FAULT RECEIVED     20\n",
      "CARD                6\n",
      "Name: Type, dtype: int64\n",
      "Reading team: home\n",
      "Reading team: away\n"
     ]
    }
   ],
   "source": [
    "##Preprocess code by @EightyFivePoint https://github.com/Friends-of-Tracking-Data-FoTD/LaurieOnTracking\n",
    "\n",
    "import Metrica_IO as mio\n",
    "import Metrica_Viz as mviz\n",
    "import Metrica_Velocities as mvel\n",
    "\n",
    "DATADIR = 'data/'\n",
    "\n",
    "game_id = 2 # let's look at sample match 2\n",
    "\n",
    "# read in the event data\n",
    "events = mio.read_event_data(DATADIR,game_id)\n",
    "\n",
    "# count the number of each event type in the data\n",
    "print( events['Type'].value_counts() )\n",
    "\n",
    "# Bit of housekeeping: unit conversion from metric data units to meters\n",
    "events = mio.to_metric_coordinates(events)\n",
    "\n",
    "# Get events by team\n",
    "home_events = events[events['Team']=='Home']\n",
    "away_events = events[events['Team']=='Away']\n",
    "\n",
    "# Frequency of each event type by team\n",
    "home_events['Type'].value_counts()\n",
    "away_events['Type'].value_counts()\n",
    "\n",
    "# Get all shots\n",
    "shots = events[events['Type']=='SHOT']\n",
    "home_shots = home_events[home_events.Type=='SHOT']\n",
    "away_shots = away_events[away_events.Type=='SHOT']\n",
    "\n",
    "# Look at frequency of each shot Subtype\n",
    "home_shots['Subtype'].value_counts()\n",
    "away_shots['Subtype'].value_counts()\n",
    "\n",
    "\n",
    "# Get the shots that led to a goal\n",
    "home_goals = home_shots[home_shots['Subtype'].str.contains('-GOAL')].copy()\n",
    "away_goals = away_shots[away_shots['Subtype'].str.contains('-GOAL')].copy()\n",
    "\n",
    "# Add a column event 'Minute' to the data frame\n",
    "home_goals['Minute'] = home_goals['Start Time [s]']/60.\n",
    "\n",
    "\n",
    "#### TRACKING DATA ####\n",
    "\n",
    "# READING IN TRACKING DATA\n",
    "tracking_home = mio.tracking_data(DATADIR,game_id,'Home')\n",
    "tracking_away = mio.tracking_data(DATADIR,game_id,'Away')\n",
    "\n",
    "\n",
    "\n",
    "# Convert positions from metrica units to meters \n",
    "tracking_home = mio.to_metric_coordinates(tracking_home)\n",
    "tracking_away = mio.to_metric_coordinates(tracking_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate player velocities\n",
    "tracking_home = mvel.calc_player_velocities(tracking_home,  filter_='moving average')\n",
    "tracking_away = mvel.calc_player_velocities(tracking_away,  filter_='moving average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider ball is inbound only (no missing ball coordinate)\n",
    "\n",
    "tracking_home_inbound = tracking_home[~pd.isna(tracking_home.ball_x)]\n",
    "tracking_away_inbound = tracking_away[~pd.isna(tracking_away.ball_x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model input\n",
    "\n",
    "To convert the data into input, we need to extract the player position and speed and feed into the model. Particularly after inspired by NFL competition solution here are the input:\n",
    "\n",
    "1. Difference of x,y position between each of home and away team player\n",
    "2. Difference of x,y velocity between each of home and away team player\n",
    "3. Difference in x,y position between each of home team players and the ball\n",
    "4. Difference in x,y position between each of away team players and the ball\n",
    "5. x,y velocty of home team player\n",
    "6. x,y velocty of away team player\n",
    "\n",
    "And hence there are 6x2 = 12 layers of input, or typically in neural network it is a 12 channels data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_faetures(tracking_home,tracking_away):\n",
    "\n",
    "    ball_loc = tracking_home_inbound[['ball_x','ball_y']].values\n",
    "\n",
    "    player_home_inbound = tracking_home_inbound[tracking_home_inbound.columns[~tracking_home_inbound.columns.str.contains('ball')]]\n",
    "    player_away_inbound = tracking_away_inbound[tracking_away_inbound.columns[~tracking_away_inbound.columns.str.contains('ball')]]\n",
    "\n",
    "\n",
    "    \n",
    "    home_x = player_home_inbound[player_home_inbound.columns[player_home_inbound.columns.str.endswith('_x')]].values\n",
    "    home_y = player_home_inbound[player_home_inbound.columns[player_home_inbound.columns.str.endswith('_y')]].values\n",
    "    home_vx = player_home_inbound[player_home_inbound.columns[player_home_inbound.columns.str.endswith('_vx')]].values\n",
    "    home_vy = player_home_inbound[player_home_inbound.columns[player_home_inbound.columns.str.endswith('_vy')]].values\n",
    "\n",
    "    away_x = player_away_inbound[player_away_inbound.columns[player_away_inbound.columns.str.endswith('_x')]].values\n",
    "    away_y = player_away_inbound[player_away_inbound.columns[player_away_inbound.columns.str.endswith('_y')]].values\n",
    "    away_vx = player_away_inbound[player_away_inbound.columns[player_away_inbound.columns.str.endswith('_vx')]].values\n",
    "    away_vy = player_away_inbound[player_away_inbound.columns[player_away_inbound.columns.str.endswith('_vy')]].values\n",
    "    \n",
    "    del player_home_inbound\n",
    "    del player_away_inbound\n",
    "    \n",
    "    player_vector = []\n",
    "\n",
    "    for frame in range(len(home_x)):\n",
    "        home_x_input = home_x[frame][~np.isnan(home_x[frame])]\n",
    "        home_y_input = home_y[frame][~np.isnan(home_y[frame])]\n",
    "        home_vx_input = home_vx[frame][~np.isnan(home_vx[frame])]\n",
    "        home_vy_input = home_vy[frame][~np.isnan(home_vy[frame])]\n",
    "\n",
    "        away_x_input = away_x[frame][~np.isnan(away_x[frame])]\n",
    "        away_y_input = away_y[frame][~np.isnan(away_y[frame])]\n",
    "        away_vx_input = away_vx[frame][~np.isnan(away_vx[frame])]\n",
    "        away_vy_input = away_vy[frame][~np.isnan(away_vy[frame])]\n",
    "\n",
    "        ball_loc_input = ball_loc[frame]\n",
    "\n",
    "        player_vector.append(player_feature(home_x_input,away_x_input,home_y_input,away_y_input,home_vx_input,away_vx_input,\n",
    "                                           home_vy_input,away_vy_input,ball_loc_input))\n",
    "    \n",
    "    return np.array(player_vector)\n",
    "\n",
    "    \n",
    "def player_feature(home_x,away_x,home_y,away_y,home_sx,away_sx,home_sy,away_sy,ball_loc):\n",
    "    if(len(home_x<11)):\n",
    "        home_x = np.pad(home_x,(11-len(home_x),0), 'constant', constant_values=-999)\n",
    "        home_y = np.pad(home_y,(11-len(home_y),0), 'constant', constant_values=-999)\n",
    "        home_sx = np.pad(home_sx,(11-len(home_sx),0), 'constant', constant_values=-999)\n",
    "        home_sy = np.pad(home_sy,(11-len(home_sy),0), 'constant', constant_values=-999)\n",
    "    if(len(away_x<11)):\n",
    "        away_x = np.pad(away_x,(11-len(away_x),0), 'constant', constant_values=-999)\n",
    "        away_y = np.pad(away_y,(11-len(away_y),0), 'constant', constant_values=-999)\n",
    "        away_sx = np.pad(away_sx,(11-len(away_sx),0), 'constant', constant_values=-999)\n",
    "        away_sy = np.pad(away_sy,(11-len(away_sy),0), 'constant', constant_values=-999)\n",
    "\n",
    "    dist_away_home_x = away_x.reshape(-1,1)-home_x.reshape(1,-1)\n",
    "    dist_away_home_sx = away_sx.reshape(-1,1)-home_sx.reshape(1,-1)\n",
    "    dist_away_home_y = away_y.reshape(-1,1)-home_y.reshape(1,-1)\n",
    "    dist_away_home_sy = away_sy.reshape(-1,1)-home_sy.reshape(1,-1)\n",
    "    dist_home_ball_x = home_x.reshape(-1,1)-np.repeat(ball_loc[0],11).reshape(1,-1)\n",
    "    dist_home_ball_y = home_y.reshape(-1,1)-np.repeat(ball_loc[1],11).reshape(1,-1)    \n",
    "    dist_away_ball_x = away_x.reshape(-1,1)-np.repeat(ball_loc[0],11).reshape(1,-1)\n",
    "    dist_away_ball_y = away_y.reshape(-1,1)-np.repeat(ball_loc[1],11).reshape(1,-1)\n",
    "    home_sx = np.repeat(home_sx,11).reshape(11,-1)\n",
    "    home_sy = np.repeat(home_sy,11).reshape(11,-1)\n",
    "    away_sx = np.repeat(away_sx,11).reshape(11,-1)\n",
    "    away_sy = np.repeat(away_sy,11).reshape(11,-1)\n",
    "    feats = [dist_away_home_x, dist_away_home_sx, dist_away_home_y,dist_away_home_sy, dist_home_ball_x,dist_home_ball_y,dist_away_ball_x,dist_away_ball_y,\n",
    "            home_sx,home_sy,away_sx,away_sy]\n",
    "    \n",
    "    return np.stack(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = create_faetures(tracking_home,tracking_away )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(feats, sctype=\"standard\"):\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    for i in range(feats.shape[1]):\n",
    "        feats_ = feats[:, i, :]\n",
    "        if sctype == \"standard\":\n",
    "            mean_ = np.mean(feats_)\n",
    "            std_ = np.std(feats_)\n",
    "            feats[:, i, :] -= mean_\n",
    "            feats[:, i, :] /= std_\n",
    "            v1.append(mean_)\n",
    "            v2.append(std_)\n",
    "        elif sctype == \"minmax\":\n",
    "            max_ = np.max(feats_)\n",
    "            min_ = np.min(feats_)\n",
    "            feats[:, i, :] = (feats_ - min_) / (max_ - min_)\n",
    "            v1.append(max_)\n",
    "            v2.append(min_)\n",
    "\n",
    "    return feats, v1, v2\n",
    "\n",
    "x, sc_mean, sc_std = scaling(x) #Standardization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Process event data as output\n",
    "\n",
    "For the target variable (or the output of model), normally people will use the chance of scroing goal in next n event (e.g. 5 events in xT and 10 events). However, sicne here is using only 1 game of training data, number of goal will be pretty low, and hence shot attempt chance in next 10 events is used for output.\n",
    "\n",
    "In order to incorperate the context of tracking data, \"shot attempt chance in next 10 events\" becomes \"tracking frame which span withnin 10 events prior to a shot attempt oppotunity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['next_event_start'] = events['Start Frame'].shift(-1).fillna(200000) \n",
    "\n",
    "events_slice = events[events.next_event_start > events['Start Frame']] #eliminate events with no duration (e.g. yellow card)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the rolling shot attempt on next 10 events\n",
    "\n",
    "events_slice['rolling_home_shot'] = ((events_slice.Type == 'SHOT') & (events_slice.Team == 'Home'))[::-1].rolling(10,1).max()[::-1].fillna(0)\n",
    "events_slice['rolling_away_shot'] = ((events_slice.Type == 'SHOT') & (events_slice.Team == 'Away'))[::-1].rolling(10,1).max()[::-1].fillna(0)\n",
    "\n",
    "s_home = pd.Series(events_slice['rolling_home_shot'].values, pd.IntervalIndex.from_arrays(events_slice['Start Frame'], events_slice['next_event_start']-1))\n",
    "s_away = pd.Series(events_slice['rolling_away_shot'].values, pd.IntervalIndex.from_arrays(events_slice['Start Frame'], events_slice['next_event_start']-1))\n",
    "\n",
    "tracking_home_inbound = tracking_home_inbound.reset_index()\n",
    "tracking_home_inbound['event_rolling_home_shot'] = tracking_home_inbound['Frame'].map(s_home).fillna(0)\n",
    "tracking_home_inbound['event_rolling_away_shot'] = tracking_home_inbound['Frame'].map(s_away).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally checking the data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Period</th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Home_11_x</th>\n",
       "      <th>Home_11_y</th>\n",
       "      <th>Home_1_x</th>\n",
       "      <th>Home_1_y</th>\n",
       "      <th>Home_2_x</th>\n",
       "      <th>Home_2_y</th>\n",
       "      <th>Home_3_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Home_7_vy</th>\n",
       "      <th>Home_7_speed</th>\n",
       "      <th>Home_8_vx</th>\n",
       "      <th>Home_8_vy</th>\n",
       "      <th>Home_8_speed</th>\n",
       "      <th>Home_9_vx</th>\n",
       "      <th>Home_9_vy</th>\n",
       "      <th>Home_9_speed</th>\n",
       "      <th>event_rolling_home_shot</th>\n",
       "      <th>event_rolling_away_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2.04</td>\n",
       "      <td>47.47846</td>\n",
       "      <td>0.68952</td>\n",
       "      <td>15.67422</td>\n",
       "      <td>15.61892</td>\n",
       "      <td>18.82878</td>\n",
       "      <td>5.01160</td>\n",
       "      <td>19.23158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454143</td>\n",
       "      <td>0.464687</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>-0.055857</td>\n",
       "      <td>0.193727</td>\n",
       "      <td>-0.291500</td>\n",
       "      <td>0.522143</td>\n",
       "      <td>0.598001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>47.46574</td>\n",
       "      <td>0.67660</td>\n",
       "      <td>15.68482</td>\n",
       "      <td>15.63660</td>\n",
       "      <td>18.83090</td>\n",
       "      <td>5.01228</td>\n",
       "      <td>19.18706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449286</td>\n",
       "      <td>0.460766</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.043714</td>\n",
       "      <td>0.186898</td>\n",
       "      <td>-0.314214</td>\n",
       "      <td>0.522143</td>\n",
       "      <td>0.609396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2.12</td>\n",
       "      <td>47.45196</td>\n",
       "      <td>0.66300</td>\n",
       "      <td>15.69330</td>\n",
       "      <td>15.65496</td>\n",
       "      <td>18.83302</td>\n",
       "      <td>5.00684</td>\n",
       "      <td>19.14360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.455430</td>\n",
       "      <td>0.170357</td>\n",
       "      <td>-0.041286</td>\n",
       "      <td>0.175289</td>\n",
       "      <td>-0.329357</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>0.627644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2.16</td>\n",
       "      <td>47.44136</td>\n",
       "      <td>0.65348</td>\n",
       "      <td>15.70390</td>\n",
       "      <td>15.67876</td>\n",
       "      <td>18.83514</td>\n",
       "      <td>5.00888</td>\n",
       "      <td>19.10120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420143</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>-0.029143</td>\n",
       "      <td>0.161649</td>\n",
       "      <td>-0.355857</td>\n",
       "      <td>0.512429</td>\n",
       "      <td>0.623873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>47.43076</td>\n",
       "      <td>0.64668</td>\n",
       "      <td>15.71556</td>\n",
       "      <td>15.70256</td>\n",
       "      <td>18.83620</td>\n",
       "      <td>5.01160</td>\n",
       "      <td>19.05668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395857</td>\n",
       "      <td>0.417444</td>\n",
       "      <td>0.151429</td>\n",
       "      <td>-0.021857</td>\n",
       "      <td>0.152998</td>\n",
       "      <td>-0.378571</td>\n",
       "      <td>0.488143</td>\n",
       "      <td>0.617738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frame  Period  Time [s]  Home_11_x  Home_11_y  Home_1_x  Home_1_y  \\\n",
       "0     51       1      2.04   47.47846    0.68952  15.67422  15.61892   \n",
       "1     52       1      2.08   47.46574    0.67660  15.68482  15.63660   \n",
       "2     53       1      2.12   47.45196    0.66300  15.69330  15.65496   \n",
       "3     54       1      2.16   47.44136    0.65348  15.70390  15.67876   \n",
       "4     55       1      2.20   47.43076    0.64668  15.71556  15.70256   \n",
       "\n",
       "   Home_2_x  Home_2_y  Home_3_x  ...  Home_7_vy  Home_7_speed  Home_8_vx  \\\n",
       "0  18.82878   5.01160  19.23158  ...   0.454143      0.464687   0.185500   \n",
       "1  18.83090   5.01228  19.18706  ...   0.449286      0.460766   0.181714   \n",
       "2  18.83302   5.00684  19.14360  ...   0.442000      0.455430   0.170357   \n",
       "3  18.83514   5.00888  19.10120  ...   0.420143      0.437259   0.159000   \n",
       "4  18.83620   5.01160  19.05668  ...   0.395857      0.417444   0.151429   \n",
       "\n",
       "   Home_8_vy  Home_8_speed  Home_9_vx  Home_9_vy  Home_9_speed  \\\n",
       "0  -0.055857      0.193727  -0.291500   0.522143      0.598001   \n",
       "1  -0.043714      0.186898  -0.314214   0.522143      0.609396   \n",
       "2  -0.041286      0.175289  -0.329357   0.534286      0.627644   \n",
       "3  -0.029143      0.161649  -0.355857   0.512429      0.623873   \n",
       "4  -0.021857      0.152998  -0.378571   0.488143      0.617738   \n",
       "\n",
       "   event_rolling_home_shot  event_rolling_away_shot  \n",
       "0                      0.0                      0.0  \n",
       "1                      0.0                      0.0  \n",
       "2                      0.0                      0.0  \n",
       "3                      0.0                      0.0  \n",
       "4                      0.0                      0.0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_home_inbound.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83272, 12, 11, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tracking_home_inbound[['event_rolling_home_shot','event_rolling_away_shot']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and training loop\n",
    "\n",
    "Here the model is created using PyTorch though it would be a pretty similar code for Keras instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training script by @takuoko1  https://www.kaggle.com/takuok/1st-place-reproduction-10feats-dev\n",
    "\n",
    "\n",
    "N_CLASSES = 2 #Home and away team shot attempt chance in next 10 events\n",
    "N_CHANNELS = 12 #number of input layer\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class CnnModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(N_CHANNELS, 128, kernel_size=1, stride=1, bias=False),\n",
    "            nn.SELU(inplace=True), #Since data has both positive and negative input using ReLU will kill half of data and decrease accuracy\n",
    "            nn.Conv2d(128, 160, kernel_size=1, stride=1, bias=False),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(160, 128, kernel_size=1, stride=1, bias=False),\n",
    "            nn.SELU(inplace=True)\n",
    "        )\n",
    "        self.pool1 = nn.AdaptiveAvgPool2d((1, 11))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 160, kernel_size=(1, 1), stride=1, bias=False),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.Conv2d(160, 96, kernel_size=(1, 1), stride=1, bias=False),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.Conv2d(96, 96, kernel_size=(1, 1), stride=1, bias=False),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.last_linear = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(96, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.sigmoid(self.last_linear(x))\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, \n",
    "                    steps_upd_logging=500, accumulation_steps=1, scheduler=None):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for step, (x, targets) in enumerate(train_loader):\n",
    "        #x= x.to(device)\n",
    "        #targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:  # Wait for several backward steps\n",
    "            optimizer.step()  # Now we can do an optimizer step\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return total_loss / (step + 1)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    true_ans_list = []\n",
    "    preds_cat = []\n",
    "    for step, (x, targets) in enumerate(val_loader):\n",
    "        #x= x.to(device)\n",
    "        #targets = targets.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "#         _, targets = targets.max(dim=1)\n",
    "        loss = criterion(logits, targets)\n",
    "        true_ans_list.append(targets.float().detach().numpy())\n",
    "        preds_cat.append(logits.float().detach().numpy())\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    all_true_ans = np.concatenate(true_ans_list, axis=0)\n",
    "    all_preds = np.concatenate(preds_cat, axis=0)\n",
    "    return all_preds, all_true_ans, val_loss / (step + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decrease the computation time, 5000 frame of tracking data is used to train the model and another 5000 is used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = np.random.choice(len(x),10000, replace=False)\n",
    "train_row = sample_row[:len(sample_row)//2]\n",
    "val_row = sample_row[len(sample_row)//2:]\n",
    "\n",
    "x_train = x[train_row]\n",
    "y_train = y[train_row]\n",
    "\n",
    "x_val = x[val_row]\n",
    "y_val = y[val_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.tensor(x_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "del train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "epochs = 50\n",
    "SEED = 71\n",
    "\n",
    "model = CnnModel(num_classes=N_CLASSES)\n",
    "#model.to(device)\n",
    "\n",
    "num_steps = len(x_train) // BATCH_SIZE\n",
    "criterion = torch.nn.BCELoss() #Binary Cross Entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler  = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=3e-3,epochs=epochs+1,steps_per_epoch=num_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set fix seed\n",
    "\n",
    "def seed_torch(seed=71):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 epoch...\n",
      "Mean train loss: 0.51975\n",
      "Mean val loss: 0.36683\n",
      "Starting 2 epoch...\n",
      "Mean train loss: 0.30027\n",
      "Mean val loss: 0.2386\n",
      "Starting 3 epoch...\n",
      "Mean train loss: 0.22934\n",
      "Mean val loss: 0.20986\n",
      "Starting 4 epoch...\n",
      "Mean train loss: 0.22356\n",
      "Mean val loss: 0.21607\n",
      "Starting 5 epoch...\n",
      "Mean train loss: 0.21943\n",
      "Mean val loss: 0.20476\n",
      "Starting 6 epoch...\n",
      "Mean train loss: 0.21503\n",
      "Mean val loss: 0.1987\n",
      "Starting 7 epoch...\n",
      "Mean train loss: 0.20454\n",
      "Mean val loss: 0.20071\n",
      "Starting 8 epoch...\n",
      "Mean train loss: 0.20596\n",
      "Mean val loss: 0.21782\n",
      "Starting 9 epoch...\n",
      "Mean train loss: 0.19535\n",
      "Mean val loss: 0.18813\n",
      "Starting 10 epoch...\n",
      "Mean train loss: 0.18835\n",
      "Mean val loss: 0.19178\n",
      "Starting 11 epoch...\n",
      "Mean train loss: 0.18317\n",
      "Mean val loss: 0.17597\n",
      "Starting 12 epoch...\n",
      "Mean train loss: 0.18161\n",
      "Mean val loss: 0.17033\n",
      "Starting 13 epoch...\n",
      "Mean train loss: 0.17903\n",
      "Mean val loss: 0.17797\n",
      "Starting 14 epoch...\n",
      "Mean train loss: 0.1819\n",
      "Mean val loss: 0.17416\n",
      "Starting 15 epoch...\n",
      "Mean train loss: 0.16717\n",
      "Mean val loss: 0.17972\n",
      "Starting 16 epoch...\n",
      "Mean train loss: 0.16277\n",
      "Mean val loss: 0.15349\n",
      "Starting 17 epoch...\n",
      "Mean train loss: 0.15414\n",
      "Mean val loss: 0.14886\n",
      "Starting 18 epoch...\n",
      "Mean train loss: 0.15367\n",
      "Mean val loss: 0.14504\n",
      "Starting 19 epoch...\n",
      "Mean train loss: 0.13927\n",
      "Mean val loss: 0.156\n",
      "Starting 20 epoch...\n",
      "Mean train loss: 0.13577\n",
      "Mean val loss: 0.15192\n",
      "Starting 21 epoch...\n",
      "Mean train loss: 0.14086\n",
      "Mean val loss: 0.23458\n",
      "Starting 22 epoch...\n",
      "Mean train loss: 0.12696\n",
      "Mean val loss: 0.11939\n",
      "Starting 23 epoch...\n",
      "Mean train loss: 0.11772\n",
      "Mean val loss: 0.09932\n",
      "Starting 24 epoch...\n",
      "Mean train loss: 0.11328\n",
      "Mean val loss: 0.11235\n",
      "Starting 25 epoch...\n",
      "Mean train loss: 0.10647\n",
      "Mean val loss: 0.1211\n",
      "Starting 26 epoch...\n",
      "Mean train loss: 0.10176\n",
      "Mean val loss: 0.1072\n",
      "Starting 27 epoch...\n",
      "Mean train loss: 0.08863\n",
      "Mean val loss: 0.11164\n",
      "Starting 28 epoch...\n",
      "Mean train loss: 0.08601\n",
      "Mean val loss: 0.09231\n",
      "Starting 29 epoch...\n",
      "Mean train loss: 0.08425\n",
      "Mean val loss: 0.08656\n",
      "Starting 30 epoch...\n",
      "Mean train loss: 0.07599\n",
      "Mean val loss: 0.07279\n",
      "Starting 31 epoch...\n",
      "Mean train loss: 0.06687\n",
      "Mean val loss: 0.07621\n",
      "Starting 32 epoch...\n",
      "Mean train loss: 0.06721\n",
      "Mean val loss: 0.06085\n",
      "Starting 33 epoch...\n",
      "Mean train loss: 0.05511\n",
      "Mean val loss: 0.05754\n",
      "Starting 34 epoch...\n",
      "Mean train loss: 0.05978\n",
      "Mean val loss: 0.05755\n",
      "Starting 35 epoch...\n",
      "Mean train loss: 0.04921\n",
      "Mean val loss: 0.05926\n",
      "Starting 36 epoch...\n",
      "Mean train loss: 0.04223\n",
      "Mean val loss: 0.05429\n",
      "Starting 37 epoch...\n",
      "Mean train loss: 0.04073\n",
      "Mean val loss: 0.05374\n",
      "Starting 38 epoch...\n",
      "Mean train loss: 0.0345\n",
      "Mean val loss: 0.03763\n",
      "Starting 39 epoch...\n",
      "Mean train loss: 0.02936\n",
      "Mean val loss: 0.04015\n",
      "Starting 40 epoch...\n",
      "Mean train loss: 0.03174\n",
      "Mean val loss: 0.05368\n",
      "Starting 41 epoch...\n",
      "Mean train loss: 0.03695\n",
      "Mean val loss: 0.03813\n",
      "Starting 42 epoch...\n",
      "Mean train loss: 0.02289\n",
      "Mean val loss: 0.02977\n",
      "Starting 43 epoch...\n",
      "Mean train loss: 0.01925\n",
      "Mean val loss: 0.02768\n",
      "Starting 44 epoch...\n",
      "Mean train loss: 0.01728\n",
      "Mean val loss: 0.02735\n",
      "Starting 45 epoch...\n",
      "Mean train loss: 0.01864\n",
      "Mean val loss: 0.02535\n",
      "Starting 46 epoch...\n",
      "Mean train loss: 0.01751\n",
      "Mean val loss: 0.02409\n",
      "Starting 47 epoch...\n",
      "Mean train loss: 0.01457\n",
      "Mean val loss: 0.02304\n",
      "Starting 48 epoch...\n",
      "Mean train loss: 0.01419\n",
      "Mean val loss: 0.02457\n",
      "Starting 49 epoch...\n",
      "Mean train loss: 0.01166\n",
      "Mean val loss: 0.02424\n",
      "Starting 50 epoch...\n",
      "Mean train loss: 0.01192\n",
      "Mean val loss: 0.02541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    seed_torch(SEED + epoch)\n",
    "\n",
    "    print(\"Starting {} epoch...\".format(epoch))\n",
    "    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, scheduler=scheduler)\n",
    "    print('Mean train loss: {}'.format(round(tr_loss, 5)))\n",
    "\n",
    "    val_pred, y_true, val_loss = validate(model, val_loader, criterion, device)\n",
    "    print('Mean val loss: {}'.format(round(val_loss, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation\n",
    "\n",
    "We can now check the error and confution matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home team error = 0.0073\n"
     ]
    }
   ],
   "source": [
    "print(\"Home team error = %1.4f\" % mean_squared_error(y_true[:,0], val_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Away team error = 0.0036\n"
     ]
    }
   ],
   "source": [
    "print(\"Away team error = %1.4f\" % mean_squared_error(y_val[:,1], val_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4660,    6],\n",
       "       [  39,  295]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix for home team\n",
    "confusion_matrix(y_true[:,0], np.round(val_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4753,   17],\n",
       "       [   4,  226]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix for away team\n",
    "confusion_matrix(y_true[:,1], np.round(val_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model can predict shot attempt chance well despite the heavy class imbalance, though still it's not that meaningful given limited data only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible future improvement\n",
    "\n",
    "It's just a simple demo of capability of neural network. Possible future improvement include:\n",
    "\n",
    "1. There are only two games of data and obviously more tracking data would help\n",
    "2. Neural network structure here is not fine tuned for soccer task and could have rooms for improvement\n",
    "3. Only a snapshot of tracking data frame is used as model input: accuracy can improve if consider past frames as well\n",
    "\n",
    "and possible many more.\n",
    "\n",
    "Also similar input structure can be used for different task e.g. pass completion probability, scenario autoencoder... etc\n",
    "\n",
    "Karun Singh has mentioned a few in Opta forum presentation: https://vimeo.com/398489039/80d8dcfb58"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
